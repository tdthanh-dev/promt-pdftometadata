# PDF to Metadata Extraction System

Há»‡ thá»‘ng trÃ­ch xuáº¥t metadata vÃ  ná»™i dung cÃ³ cáº¥u trÃºc tá»« file PDF sá»­ dá»¥ng Google Gemini AI + PostgreSQL pgvector.

## âœ¨ TÃ­nh nÄƒng

- ğŸ¤– Sá»­ dá»¥ng **Gemini 2.5 Flash** - Model AI máº¡nh nháº¥t hiá»‡n táº¡i
- ğŸ“„ TrÃ­ch xuáº¥t metadata tá»« vÄƒn báº£n PDF (Quyáº¿t Ä‘á»‹nh, ThÃ´ng bÃ¡o, Quy cháº¿...)
- ğŸ¯ Schema validation vá»›i Pydantic v2
- ğŸ” PhÃ¢n tÃ­ch chi tiáº¿t theo chunks (má»—i Ä‘iá»u khoáº£n, má»—i dÃ²ng báº£ng = 1 chunk)
- ğŸ†” Tá»± Ä‘á»™ng táº¡o UUID cÃ³ Ã½ nghÄ©a cho documents vÃ  chunks
- ğŸ“Š TrÃ­ch xuáº¥t thÃ´ng tin: Há»c phÃ­, KhÃ³a Ã¡p dá»¥ng, Äiá»ƒm rÃ¨n luyá»‡n...
- ğŸ˜ **PostgreSQL + pgvector** cho vector similarity search
- ğŸ” **Semantic search** vá»›i embeddings (768 dimensions)
- ğŸ’¾ LÆ°u trá»¯ persistent vá»›i Docker volume

## ğŸš€ Schema Metadata

### Document Metadata
- DOC_ID, FILE_NAME, DOC_TITLE
- DOC_TYPE, ISSUE_NUMBER, ISSUE_DATE
- ISSUING_AUTHORITY, ISSUING_DEPT
- EFFECTIVE_DATE, EXPIRATION_DATE
- MAJOR_TOPIC

### Chunk Metadata
- CHUNK_ID, PAGE_NUMBER, SECTION_TITLE
- CHUNK_TOPIC, CONTENT_TYPE
- SPECIFIC_TARGET, APPLICABLE_COHORT
- VALUE, UNIT, KEYWORDS
- chunk_text

## ğŸ“¦ CÃ i Ä‘áº·t

### Option 1: Sá»­ dá»¥ng Docker (Khuyáº¿n nghá»‹)

```bash
# Clone repository
git clone https://github.com/tdthanh-dev/promt-pdftometadata.git
cd promt-pdftometadata

# Khá»Ÿi Ä‘á»™ng PostgreSQL vá»›i pgvector
docker-compose up -d

# CÃ i Ä‘áº·t Python dependencies
pip install -r requirements.txt

# Cáº¥u hÃ¬nh environment
cp .env.example .env
# Sá»­a .env vá»›i GEMINI_API_KEY cá»§a báº¡n
```

ğŸ“– **Xem chi tiáº¿t:** [DOCKER_SETUP.md](DOCKER_SETUP.md)

### Option 2: Manual Installation

```bash
pip install google-genai pydantic python-dotenv psycopg2-binary
```

## âš™ï¸ Cáº¥u hÃ¬nh

Táº¡o file `.env`:
```
GEMINI_API_KEY=your_api_key_here
```

## ğŸ¯ Sá»­ dá»¥ng

### 1. TrÃ­ch xuáº¥t PDF
```python
python main.py
```

Chá»‰nh sá»­a tÃªn file PDF trong `main.py`:
```python
PDF_FILE_TO_PROCESS = 'your_file.pdf'
```

### 2. LÆ°u vÃ o PostgreSQL vá»›i embeddings
```python
from pgvector_storage import PgVectorStorage
import json

storage = PgVectorStorage()

# Load tá»« output.json
with open('output.json', 'r', encoding='utf-8') as f:
    doc_data = json.load(f)
    storage.save_document(doc_data)
```

### 3. TÃ¬m kiáº¿m semantic
```python
# TÃ¬m kiáº¿m theo ngá»¯ nghÄ©a
results = storage.semantic_search(
    query="há»c phÃ­ chÆ°Æ¡ng trÃ¬nh tiÃªn tiáº¿n khÃ³a 2024",
    limit=5
)

for result in results:
    print(f"{result['chunk_topic']}: {result['chunk_text']}")
    print(f"Similarity: {result['similarity']:.4f}\n")
```

## ğŸ“ Files

- `main.py` - Script chÃ­nh Ä‘á»ƒ xá»­ lÃ½ PDF
- `pgvector_storage.py` - PostgreSQL + pgvector storage & search
- `check_models.py` - Kiá»ƒm tra models cÃ³ sáºµn vá»›i API key
- `docker-compose.yml` - Docker setup cho PostgreSQL
- `init.sql` - Database schema vá»›i pgvector
- `output.json` - Káº¿t quáº£ trÃ­ch xuáº¥t (tá»± Ä‘á»™ng táº¡o)
- `DOCKER_SETUP.md` - HÆ°á»›ng dáº«n chi tiáº¿t Docker

## ğŸ¨ VÃ­ dá»¥ Output

```json
{
  "document_metadata": {
    "DOC_ID": "DRL_2024_2025_TB_001",
    "DOC_TITLE": "Vá» viá»‡c cÃ´ng bá»‘ dá»± tháº£o...",
    "DOC_TYPE": "THÃ”NG BÃO",
    "ISSUE_DATE": "2025-10-13"
  },
  "chunk_metadata": [
    {
      "CHUNK_ID": "DRL_2024_2025_TB_001_CHUNK_001",
      "CHUNK_TOPIC": "CÄƒn cá»© vÃ  má»¥c Ä‘Ã­ch thÃ´ng bÃ¡o",
      "APPLICABLE_COHORT": "NÄƒm há»c 2024 - 2025",
      "chunk_text": "..."
    }
  ]
}
```

## ğŸ”¥ Model Support

Há»— trá»£ cÃ¡c Gemini models:
- â­ **gemini-2.5-flash** (Khuyáº¿n nghá»‹ - Ä‘ang dÃ¹ng)
- ğŸ’ gemini-2.5-pro
- âš¡ gemini-2.0-flash-exp

## ğŸ“„ License

MIT

## ğŸ‘¨â€ğŸ’» Author

Created with â¤ï¸ using Google Gemini AI
