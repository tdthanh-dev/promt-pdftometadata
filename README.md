# ü§ñ ChatBot - Tr·ª£ l√Ω h·ªçc v·ª• t·ª± ƒë·ªông

H·ªá th·ªëng tr√≠ch xu·∫•t metadata t·ª´ t√†i li·ªáu PDF h·ªçc v·ª• v√† x√¢y d·ª±ng chatbot h·ªó tr·ª£ sinh vi√™n tra c·ª©u th√¥ng tin th√¥ng qua semantic search.

## üìã T·ªïng quan

- **Input**: PDF files (Th√¥ng b√°o CTDT, Quy ƒë·ªãnh h·ªçc ph√≠, Quy ch·∫ø ƒë√†o t·∫°o, ...)
- **Processing**: Gemini 2.0 Flash v·ªõi Structured Output
- **Storage**: PostgreSQL + pgvector (768-dimensional embeddings)
- **Search**: Vector similarity search v·ªõi HNSW index

## üóÇÔ∏è C·∫•u tr√∫c d·ª± √°n

```
ChatBot/
‚îú‚îÄ‚îÄ data/                          # Data directory (kh√¥ng commit l√™n Git)
‚îÇ   ‚îú‚îÄ‚îÄ raw_pdfs/                  # PDF files g·ªëc
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ THONGBAO/              # 34 files CTDT c√°c kh√≥a, ng√†nh
‚îÇ   ‚îú‚îÄ‚îÄ processed/                 # K·∫øt qu·∫£ x·ª≠ l√Ω
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ json/                  # Structured metadata
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ csv/                   # Human-readable format
‚îÇ   ‚îî‚îÄ‚îÄ logs/                      # Processing logs
‚îÇ
‚îú‚îÄ‚îÄ src/                           # Source code
‚îÇ   ‚îú‚îÄ‚îÄ extractors/                # PDF extraction logic
‚îÇ   ‚îú‚îÄ‚îÄ pgvector_storage.py        # PostgreSQL + pgvector storage
‚îÇ   ‚îî‚îÄ‚îÄ chatbot_storage.py         # Legacy storage (deprecated)
‚îÇ
‚îú‚îÄ‚îÄ scripts/                       # Utility scripts
‚îÇ   ‚îî‚îÄ‚îÄ batch_process.py           # Batch processing for multiple PDFs
‚îÇ
‚îú‚îÄ‚îÄ main.py                        # Single file processor
‚îú‚îÄ‚îÄ docker-compose.yml             # PostgreSQL + pgvector setup
‚îú‚îÄ‚îÄ init.sql                       # Database schema
‚îú‚îÄ‚îÄ requirements.txt               # Python dependencies
‚îú‚îÄ‚îÄ .env                           # Environment variables (API keys)
‚îî‚îÄ‚îÄ ARCHITECTURE.md                # Detailed architecture docs
```

## üöÄ Quick Start

### 1Ô∏è‚É£ Setup m√¥i tr∆∞·ªùng

```bash
# Clone repository
git clone https://github.com/tdthanh-dev/promt-pdftometadata.git
cd ChatBot

# T·∫°o virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# C√†i ƒë·∫∑t dependencies
pip install -r requirements.txt

# T·∫°o file .env
echo "GEMINI_API_KEY=your_api_key_here" > .env
```

### 2Ô∏è‚É£ Kh·ªüi ƒë·ªông Database

```bash
# Start PostgreSQL + pgvector
docker-compose up -d

# Verify database
docker ps
docker exec chatbot_pgvector psql -U chatbot_user -d chatbot_db -c "\dt"
```

### 3Ô∏è‚É£ X·ª≠ l√Ω PDF files

**Option A: X·ª≠ l√Ω 1 file**
```bash
python main.py
# Nh·∫≠p ƒë∆∞·ªùng d·∫´n PDF khi ƒë∆∞·ª£c h·ªèi
```

**Option B: X·ª≠ l√Ω h√†ng lo·∫°t (Recommended)**
```bash
# X·ª≠ l√Ω to√†n b·ªô THONGBAO folder (34 files)
python scripts/batch_process.py --input data/raw_pdfs/THONGBAO --output data/processed

# X·ª≠ l√Ω 5 files ƒë·∫ßu ti√™n (ƒë·ªÉ test)
python scripts/batch_process.py --input data/raw_pdfs/THONGBAO --output data/processed --limit 5

# Reprocess t·∫•t c·∫£ (overwrite)
python scripts/batch_process.py --input data/raw_pdfs/THONGBAO --output data/processed --no-skip
```

### 4Ô∏è‚É£ Load v√†o Database

```bash
# TODO: Script ƒëang ph√°t tri·ªÉn
python scripts/migrate_to_db.py --input data/processed/json
```

### 5Ô∏è‚É£ Test Semantic Search

```bash
# TODO: API ƒëang ph√°t tri·ªÉn
python scripts/test_search.py --query "H·ªçc ph√≠ kh√≥a 2025"
```

## üìä Database Schema

### Table: `documents`
L∆∞u metadata c·∫•p t√†i li·ªáu

| Column | Type | Description |
|--------|------|-------------|
| `id` | SERIAL | Primary key |
| `doc_id` | VARCHAR(100) | Unique document ID |
| `file_name` | VARCHAR(255) | Original filename |
| `doc_title` | TEXT | Document title |
| `doc_type` | VARCHAR(50) | "Th√¥ng b√°o", "Quy ƒë·ªãnh", ... |
| `issue_number` | VARCHAR(100) | S·ªë hi·ªáu vƒÉn b·∫£n |
| `issuing_authority` | VARCHAR(255) | C∆° quan ban h√†nh |
| `issue_date` | DATE | Ng√†y ban h√†nh |
| `major_topic` | VARCHAR(100) | Ch·ªß ƒë·ªÅ ch√≠nh |

### Table: `chunks`
L∆∞u metadata c·∫•p ƒëo·∫°n vƒÉn + vector embeddings

| Column | Type | Description |
|--------|------|-------------|
| `id` | SERIAL | Primary key |
| `chunk_id` | VARCHAR(150) | Unique chunk ID |
| `doc_id` | VARCHAR(100) | Foreign key ‚Üí documents |
| `page_number` | INTEGER | S·ªë trang |
| `chunk_topic` | VARCHAR(255) | Ch·ªß ƒë·ªÅ ƒëo·∫°n vƒÉn |
| `content_type` | VARCHAR(100) | "ƒê·∫°i tr√†", "CLCQ", ... |
| `applicable_cohort` | VARCHAR(100) | "Kh√≥a 2024", "Kh√≥a 2025" |
| `chunk_text` | TEXT | N·ªôi dung ƒë·∫ßy ƒë·ªß |
| `embedding` | vector(768) | Vector embedding |

## üîß Configuration

### Environment Variables (`.env`)

```env
# Gemini API
GEMINI_API_KEY=your_gemini_api_key

# PostgreSQL
POSTGRES_USER=chatbot_user
POSTGRES_PASSWORD=Thanh1410@
POSTGRES_DB=chatbot_db
POSTGRES_PORT=5433
```

### Docker Compose

```yaml
services:
  pgvector:
    image: pgvector/pgvector:pg16
    container_name: chatbot_pgvector
    ports:
      - "5433:5432"
    environment:
      POSTGRES_USER: chatbot_user
      POSTGRES_PASSWORD: Thanh1410@
      POSTGRES_DB: chatbot_db
    volumes:
      - pgvector_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
```

## üìà Processing Stats

### THONGBAO Folder (34 files CTDT)

- **Total files**: 34 PDFs
- **Estimated time**: ~17 ph√∫t (30s/file)
- **Output size**: 
  - JSON: ~1.7 MB
  - Database: ~5 MB (with embeddings)
- **Chunks**: ~500-1000 chunks t·ªïng c·ªông

## üõ†Ô∏è Development

### Th√™m PDF m·ªõi

```bash
# 1. Copy PDF v√†o th∆∞ m·ª•c ph√π h·ª£p
cp new_document.pdf data/raw_pdfs/QUY_DINH/

# 2. Ch·∫°y batch processor
python scripts/batch_process.py --input data/raw_pdfs/QUY_DINH --output data/processed

# 3. Load v√†o database
python scripts/migrate_to_db.py --input data/processed/json/new_document_output.json
```

### Update Schema

```bash
# 1. S·ª≠a file init.sql
# 2. Restart database
docker-compose down
docker-compose up -d
```

## üìù Logs

Logs ƒë∆∞·ª£c l∆∞u t·∫°i `data/logs/batch_YYYYMMDD_HHMMSS.log`

```bash
# Xem log m·ªõi nh·∫•t
Get-ChildItem data/logs | Sort-Object LastWriteTime -Descending | Select-Object -First 1 | Get-Content
```

## üêõ Troubleshooting

### Database connection failed

```bash
# Check container status
docker ps

# Check logs
docker logs chatbot_pgvector

# Restart container
docker-compose restart
```

### PDF extraction failed

```bash
# Check API key
cat .env | grep GEMINI_API_KEY

# Check file encoding
file data/raw_pdfs/THONGBAO/filename.pdf

# Test with single file
python main.py
```

## üìö Documentation

- [ARCHITECTURE.md](ARCHITECTURE.md) - Detailed architecture & design decisions
- [docker-compose.yml](docker-compose.yml) - Infrastructure setup
- [init.sql](init.sql) - Database schema

## ü§ù Contributing

1. Fork repository
2. Create feature branch: `git checkout -b feature/new-feature`
3. Commit changes: `git commit -am 'Add new feature'`
4. Push to branch: `git push origin feature/new-feature`
5. Submit Pull Request

## üìÑ License

MIT License - see [LICENSE](LICENSE) file for details

## üë• Authors

- **tdthanh-dev** - Initial work - [GitHub](https://github.com/tdthanh-dev)

## üôè Acknowledgments

- Gemini 2.0 Flash for structured PDF extraction
- pgvector for efficient vector similarity search
- PostgreSQL for reliable data storage
